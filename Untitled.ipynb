{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function inputs:\n",
    "data_folder = '..\\Data\\Level_0\\Falkor19\\KT15'\n",
    "output_path = '..\\Data\\Level_1\\Falkor19\\KT15'\n",
    "sea_serial = 7417\n",
    "sky_serial = 7409\n",
    "experiment = 'Falkor19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\Data\\\\Level_0\\\\Falkor19\\\\KT15\\\\2019_Falkor_326_065848.txt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(data_folder + '\\*.txt')\n",
    "files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009961128234863281\n"
     ]
    }
   ],
   "source": [
    "#loop through filenames and import to pandas dataframes\n",
    "import time \n",
    "\n",
    "start = time.time()\n",
    "df = (pd.read_csv(f, delimiter='\\s+', skiprows=1, header=None,                                                  #treat whitespace as the delimeter, ignore the header line\n",
    "                  usecols=[0,1,2,3,4,5], names=['Date','Time','SeaRef','SeaTemp','SkyRef','SkyTemp'],           #use the first 6 columns, and name them as specified\n",
    "                  parse_dates={'DateTime':[0,1]}, index_col=0,                                                  #parse the first two columns as a single DateTime, and make it the index column\n",
    "                  na_values=['AMB','TIMEOUT','ERROR'],                                                          #list of other things the parser might encounter in these files, that should be treated like NaNs\n",
    "                  dtype={'SeaRef':np.float64, 'SeaTemp':np.float64, 'SkyRef':np.float64, 'SkyTemp':np.float64}, #explicitly specify that data columns must be 64-bit floating point numbers\n",
    "                  error_bad_lines=False, warn_bad_lines=True).dropna(axis='index',how='any',inplace=True)       #drop any bad lines or rows with NaN in them\n",
    "      for f in glob.glob(data_folder + '\\*.txt'))                                                               #iterate over all the text files found in the data_folder\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'concat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3af5dc3447a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mkt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'generator' object has no attribute 'concat'"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "kt = df.concat()\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing it with a classic for loop\n",
    "takes about 7 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/22 [00:00<?, ?it/s]\n",
      "  5%|███▊                                                                               | 1/22 [00:15<05:18, 15.18s/it]\n",
      "  9%|███████▌                                                                           | 2/22 [00:27<04:48, 14.43s/it]\n",
      " 14%|███████████▎                                                                       | 3/22 [00:42<04:34, 14.47s/it]\n",
      " 18%|███████████████                                                                    | 4/22 [00:49<03:40, 12.24s/it]\n",
      " 23%|██████████████████▊                                                                | 5/22 [00:55<02:57, 10.42s/it]\n",
      " 27%|██████████████████████▋                                                            | 6/22 [01:10<03:05, 11.61s/it]\n",
      " 32%|██████████████████████████▍                                                        | 7/22 [01:25<03:11, 12.75s/it]\n",
      " 36%|██████████████████████████████▏                                                    | 8/22 [01:40<03:06, 13.32s/it]\n",
      " 41%|█████████████████████████████████▉                                                 | 9/22 [01:52<02:50, 13.09s/it]\n",
      " 45%|█████████████████████████████████████▎                                            | 10/22 [02:06<02:40, 13.36s/it]\n",
      " 50%|█████████████████████████████████████████                                         | 11/22 [02:20<02:26, 13.36s/it]\n",
      " 55%|████████████████████████████████████████████▋                                     | 12/22 [02:34<02:16, 13.61s/it]\n",
      " 59%|████████████████████████████████████████████████▍                                 | 13/22 [03:03<02:43, 18.22s/it]\n",
      " 64%|████████████████████████████████████████████████████▏                             | 14/22 [03:17<02:15, 16.94s/it]\n",
      " 68%|███████████████████████████████████████████████████████▉                          | 15/22 [04:41<04:21, 37.30s/it]\n",
      " 73%|███████████████████████████████████████████████████████████▋                      | 16/22 [04:55<03:01, 30.26s/it]\n",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 17/22 [05:24<02:29, 29.81s/it]\n",
      " 82%|███████████████████████████████████████████████████████████████████               | 18/22 [05:38<01:39, 24.91s/it]\n",
      " 86%|██████████████████████████████████████████████████████████████████████▊           | 19/22 [05:52<01:05, 21.86s/it]\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▌       | 20/22 [06:06<00:39, 19.53s/it]\n",
      " 95%|██████████████████████████████████████████████████████████████████████████████▎   | 21/22 [06:21<00:18, 18.19s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [06:43<00:00, 19.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403.7713885307312\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "files = glob.glob(data_folder + '\\*.txt')\n",
    "li = []\n",
    "start = time.time()\n",
    "for filepath in tqdm(files):\n",
    "    df = pd.read_csv(filepath,                                                                                     #filename to read in\n",
    "                     delimiter='\\s+', skiprows=1, header=None,                                                     #treat whitespace as the delimeter, ignore the header line\n",
    "                     usecols=[0,1,2,3,4,5], names=['Date','Time','SeaRef','SeaTemp','SkyRef','SkyTemp'],           #use the first 6 columns, and name them as specified\n",
    "                     parse_dates={'DateTime':[0,1]}, index_col=0,                                                  #parse the first two columns as a single DateTime, and make it the index column\n",
    "                     na_values=['AMB','TIMEOUT','ERROR'],                                                                            #list of other things the parser might encounter in these files, that should be treated like NaNs\n",
    "                     dtype={'SeaRef':np.float64, 'SeaTemp':np.float64, 'SkyRef':np.float64, 'SkyTemp':np.float64}, #explicitly specify that data columns must be 64-bit floating point numbers\n",
    "                     error_bad_lines=False, warn_bad_lines=True)                                                   #if there is a bad line in the data file, drop it from the file and show a warning, but continue parsing\n",
    "    df.dropna(axis='index',how='any',inplace=True)                                                                 #drop any rows that have a NaN value in them\n",
    "    \n",
    "    li.append(df)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10170221328735352\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "kt = pd.concat(li, axis=0)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3690192699432373\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "kt.to_pickle(output_path+f'\\{experiment}_KT15_{sea_serial}_{sky_serial}.p')\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:   (DateTime: 2972671)\n",
       "Coordinates:\n",
       "  * DateTime  (DateTime) datetime64[ns] 2019-11-21T04:34:36.153000 ... 2019-12-18T19:56:40.848000\n",
       "Data variables:\n",
       "    SeaRef    (DateTime) float64 31.51 31.51 31.51 31.51 ... 35.36 35.36 35.36\n",
       "    SeaTemp   (DateTime) float64 27.94 27.98 27.9 27.92 ... 28.4 28.3 28.26\n",
       "    SkyRef    (DateTime) float64 31.69 31.69 31.69 31.69 ... 35.2 35.2 35.19\n",
       "    SkyTemp   (DateTime) float64 22.4 22.38 22.31 22.33 ... -2.39 -2.39 -2.5\n",
       "Attributes:\n",
       "    experiment:  Falkor19\n",
       "    sea_serial:  7417\n",
       "    sky_serial:  7409"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xarray\n",
    "ds = xarray.Dataset.from_dataframe(kt)\n",
    "ds.attrs['experiment'] = experiment\n",
    "ds.attrs['sea_serial'] = sea_serial\n",
    "ds.attrs['sky_serial'] = sky_serial\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(output_path+f'/{experiment}_KT15_{sea_serial}_{sky_serial}.cdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xarray.open_dataset('test.cdf')\n",
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
